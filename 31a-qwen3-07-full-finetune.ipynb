{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5258273-5283-465d-96bb-2a24bd7b7030",
   "metadata": {},
   "source": [
    "# Finetune a Qwen3 model with 700 million parameters\n",
    "\n",
    "We use a self-curated dataset with [arXiv](https://arxiv.org/) as a basis. The whole dataset is available from [Kaggle](https://www.kaggle.com/datasets/Cornell-University/arxiv). The dataset was filtered to have either `LLM` (only as a whole word), `Large Language Model`, `GRPO` or `GSPO` in the title of the abstract. \n",
    "\n",
    "We use the following system prompt:\n",
    "```\n",
    "You are an educated researcher and always answer in correct scientific terms.\n",
    "You are very deep into LLMs and its methodologies. You are very creative.\n",
    "```\n",
    "\n",
    "The model should learn how to write abstracts about a certain topic. An example user prompt would be:\n",
    "```\n",
    "Write an abstract with the title 'Few-shot training LLMs for project-specific code-summarization'\n",
    "```\n",
    "\n",
    "The example abstract is taken from arXiv, so the answer will be:\n",
    "```\n",
    "Very large language models (LLMs), such as GPT-3 and Codex have achieved\n",
    "state-of-the-art performance on several natural-language tasks, and show great\n",
    "promise also for code. A particularly exciting aspect of LLMs is their knack\n",
    "for few-shot and zero-shot learning: they can learn to perform a task with very\n",
    "few examples. Few-shotting has particular synergies in software engineering,\n",
    "where there are a lot of phenomena (identifier names, APIs, terminology, coding\n",
    "patterns) that are known to be highly project-specific. However,\n",
    "project-specific data can be quite limited, especially early in the history of\n",
    "a project; thus the few-shot learning capacity of LLMs might be very relevant.\n",
    "In this paper, we investigate the use few-shot training with the very large GPT\n",
    "(Generative Pre-trained Transformer) Codex model, and find evidence suggesting\n",
    "that one can significantly surpass state-of-the-art models for\n",
    "code-summarization, leveraging project-specific training.\n",
    "```\n",
    "\n",
    "If finetuning works, we will observe that the models know about `GRPO` which\n",
    "was introduced *after* the knowledge cutoff. Moreover, the models should adhere\n",
    "to the format and scientific language of the abstract.\n",
    "\n",
    "Implementation ideas and parts of the script from https://www.philschmid.de/fine-tune-llms-in-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854dde0d-4501-4708-9d00-7ce258349e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from transformers we just need the AutoTokenizer, the kernel comes from liger\n",
    "from transformers import AutoTokenizer\n",
    "# trl is the training framework from Hugging Face\n",
    "from trl import SFTTrainer, ModelConfig, SFTConfig\n",
    "# trl uses a dataset for training. Hugging Face provides theses datasets, but we have our own\n",
    "from datasets import load_dataset\n",
    "# much faster kernel\n",
    "from liger_kernel.transformers import AutoLigerKernelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fd4c2-e302-4fed-9027-1ff4b2790f13",
   "metadata": {},
   "source": [
    "# Arguments and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96929804-9ddb-4a58-b399-1c593aaba716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Qwen/Qwen3-0.6B'\n",
    "dataset_name = 'llm-abstract-dataset.jsonl.xz'\n",
    "output_dir = \"runs/\" + model_name.split(\"/\")[-1] + \"-\" + dataset_name.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac60180-1909-4ef8-922d-a0e64b96fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelConfig(model_name_or_path=model_name, \n",
    "                         model_revision='main', \n",
    "                         torch_dtype='bfloat16', \n",
    "                         trust_remote_code=False, \n",
    "                         attn_implementation='flash_attention_2', \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405143e-5f82-4e74-9933-529788082a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "     output_dir=output_dir,    \n",
    "     num_train_epochs=4,\n",
    "     bf16=True,\n",
    "     packing=True,\n",
    "     max_length=1024,\n",
    "     per_device_train_batch_size=8,\n",
    "     gradient_accumulation_steps=2,\n",
    "     gradient_checkpointing=True,\n",
    "     gradient_checkpointing_kwargs = { \"use_reentrant\": False },\n",
    "     learning_rate=2.0e-4,\n",
    "     lr_scheduler_type=\"constant\",\n",
    "     use_liger_kernel=True,\n",
    "     warmup_ratio=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73942c34-4e2a-4d46-8dce-a295d0e34389",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83398831-7cd5-4fac-8aef-312d1954ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"json\", data_files=dataset_name, split=\"train\")\n",
    "\n",
    "f'Dataset with {len(train_dataset)} samples and the following features: {train_dataset.features}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee0aab-36af-4e80-872e-b64f40b12dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32877220-7682-4ce2-81af-5db5a6cef9f6",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292dcff7-47b4-4674-80ba-df57ce94743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None: \n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9da573-6004-4f17-b9b1-428899627050",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811aec60-1f3a-4e0f-aed6-95a9387644d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model kwargs\n",
    "model_kwargs = dict(\n",
    "    revision=model_args.model_revision, # What revision from Huggingface to use, defaults to main\n",
    "    trust_remote_code=model_args.trust_remote_code, # Whether to trust the remote code, this also you to fine-tune custom architectures\n",
    "    attn_implementation=model_args.attn_implementation, # What attention implementation to use, defaults to flash_attention_2\n",
    "    dtype=model_args.torch_dtype, # What torch dtype to use, defaults to auto\n",
    "    use_cache=False if training_args.gradient_checkpointing else True, # Whether\n",
    "    low_cpu_mem_usage=True,  # Reduces memory usage on CPU for loading the model\n",
    "    device_map=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4b5c6-c6c2-4b9c-85fc-1f7c4523a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoLigerKernelForCausalLM.from_pretrained(model_args.model_name_or_path, **model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a00b76-38ee-409b-b0c3-5429d093285e",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e11222-9e27-4fdc-8ff9-2e74b61b3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fcd2bf-5285-461d-ade4-4329f3aa7e5b",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a4c33-507e-4b69-8117-77f62579a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()\n",
    "# log metrics\n",
    "metrics = train_result.metrics\n",
    "metrics['train_samples'] = len(train_dataset)\n",
    "trainer.save_metrics('train', metrics)\n",
    "trainer.save_state()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b2438-af85-4869-979d-431a98f712ab",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6e15c-a5c0-4370-8edd-be739bf1981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore k,v cache for fast inference\n",
    "trainer.model.config.use_cache = True\n",
    "trainer.save_model(training_args.output_dir)\n",
    "tokenizer.save_pretrained(training_args.output_dir)\n",
    "f\"saved to {training_args.output_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7418cf-bb5e-4761-825e-d0793bac96d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "finetuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
